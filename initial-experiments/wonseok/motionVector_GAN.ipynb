{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PXoUPTZjgH6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "pUHr7XeqgqVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def extract_sprites_horizontal(sprite_sheet_paths, num_frames, output_dir):\n",
        "    # Check if output directory exists, if not, create it\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for sprite_sheet_path in sprite_sheet_paths:\n",
        "        sprite_sheet = cv2.imread(sprite_sheet_path)\n",
        "        if sprite_sheet is None:\n",
        "            print(f\"Failed to load sprite sheet: {sprite_sheet_path}\")\n",
        "            continue\n",
        "\n",
        "        # Get the dimensions of the sprite sheet\n",
        "        sheet_height, sheet_width, _ = sprite_sheet.shape\n",
        "        frame_width = sheet_width // num_frames\n",
        "\n",
        "        # Extract each frame\n",
        "        for i in range(num_frames):\n",
        "            frame = sprite_sheet[:, i * frame_width:(i + 1) * frame_width]\n",
        "            frame_filename = os.path.join(output_dir, f\"frame_{i+1}.png\")\n",
        "            cv2.imwrite(frame_filename, frame)\n",
        "            print(f\"Saved frame {i+1} to {frame_filename}\")\n",
        "\n",
        "# Example usage\n",
        "sprite_sheet_paths = ['./Walk_City_men_1_10f.png']  # Path to your sprite sheet\n",
        "num_frames = 10  # Total number of frames in the sprite sheet\n",
        "output_dir = \"output_frames\"  # Directory to save the frames\n",
        "\n",
        "extract_sprites_horizontal(sprite_sheet_paths, num_frames, output_dir)"
      ],
      "metadata": {
        "id": "BEA0McAwgzwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# Step 1: Load frames from the output directory\n",
        "def load_frames_from_dir(output_dir):\n",
        "    frames = []\n",
        "    frame_files = sorted([f for f in os.listdir(output_dir) if f.endswith('.png')])\n",
        "\n",
        "    for file in frame_files:\n",
        "        frame_path = os.path.join(output_dir, file)\n",
        "        frame = cv2.imread(frame_path, cv2.IMREAD_GRAYSCALE)  # Load in grayscale for optical flow\n",
        "        frames.append(frame)\n",
        "\n",
        "    return frames\n",
        "\n",
        "# Example usage\n",
        "output_dir = \"output_frames\"\n",
        "frames = load_frames_from_dir(output_dir)\n",
        "\n",
        "# Step 2: Compute motion vectors (Optical Flow)\n",
        "motion_vectors = []\n",
        "prev_frame = frames[0]\n",
        "\n",
        "for i in range(1, len(frames)):\n",
        "    next_frame = frames[i]\n",
        "\n",
        "    # Calculate optical flow using Farneback method\n",
        "    flow = cv2.calcOpticalFlowFarneback(prev_frame, next_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "    # Append flow (motion vectors) for each frame\n",
        "    motion_vectors.append(flow)\n",
        "\n",
        "    prev_frame = next_frame\n",
        "\n",
        "# Now, you have motion_vectors ready for further use\n"
      ],
      "metadata": {
        "id": "JRipqnGph53k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will use Farneback Optical Flow to estimate motion vectors between consecutive frames\n",
        "# Parameters can be tuned to better match the small movement between sprite frames\n",
        "\n",
        "motion_vectors = []\n",
        "prev_frame = frames[0]\n",
        "\n",
        "# Compute optical flow between each consecutive frame\n",
        "for i in range(1, num_frames):\n",
        "    next_frame = frames[i]\n",
        "\n",
        "    # Calculate optical flow using Farneback method\n",
        "    flow = cv2.calcOpticalFlowFarneback(prev_frame, next_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "\n",
        "    # Append flow (motion vectors) for each frame\n",
        "    motion_vectors.append(flow)\n",
        "\n",
        "    prev_frame = next_frame\n",
        "\n",
        "# Let's visualize the motion vectors for the first frame transition to confirm the results\n",
        "magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "\n",
        "# Create a blank image to visualize the flow\n",
        "hsv = np.zeros_like(cv2.cvtColor(frames[0], cv2.COLOR_GRAY2BGR))\n",
        "hsv[..., 1] = 255\n",
        "\n",
        "# Use the magnitude and angle to create a visualization\n",
        "hsv[..., 0] = angle * 180 / np.pi / 2\n",
        "hsv[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
        "\n",
        "# Convert to BGR for display\n",
        "flow_rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "# Display the motion vector visualization\n",
        "plt.imshow(flow_rgb)\n",
        "plt.title(\"Optical Flow between Frame 1 and Frame 2\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BeFQ_SLXgIMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Preparing the data\n",
        "\n",
        "class SpriteDataset(Dataset):\n",
        "    def __init__(self, frames, motion_vectors):\n",
        "        self.frames = frames\n",
        "        self.motion_vectors = motion_vectors\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.motion_vectors)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        first_frame = self.frames[idx]  # Input: first frame\n",
        "        motion_vector = self.motion_vectors[idx]  # Input: motion vector between frame idx and idx+1\n",
        "        next_frame = self.frames[idx + 1]  # Target: the next frame to be generated\n",
        "\n",
        "        # Normalize data for the network (float conversion for PyTorch tensors)\n",
        "        first_frame = torch.tensor(first_frame).unsqueeze(0).float() / 255.0\n",
        "        next_frame = torch.tensor(next_frame).unsqueeze(0).float() / 255.0\n",
        "        motion_vector = torch.tensor(motion_vector).float()\n",
        "\n",
        "        return first_frame, motion_vector, next_frame\n",
        "\n",
        "# Create the dataset\n",
        "sprite_dataset = SpriteDataset(frames, motion_vectors)\n",
        "data_loader = DataLoader(sprite_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Step 2: Defining the GAN structure\n",
        "\n",
        "# Generator: takes the first frame and motion vector as input and generates the next frame\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = nn.Linear(128*128 + 128*128*2, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 128*128)\n",
        "\n",
        "    def forward(self, frame, motion_vector):\n",
        "        # Flatten the frame and motion vector\n",
        "        frame = frame.view(frame.size(0), -1)\n",
        "        motion_vector = motion_vector.view(motion_vector.size(0), -1)\n",
        "\n",
        "        # Concatenate frame and motion vector\n",
        "        x = torch.cat([frame, motion_vector], dim=1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.tanh(self.fc2(x))\n",
        "\n",
        "        # Reshape back to image format\n",
        "        x = x.view(-1, 1, 128, 128)\n",
        "        return x\n",
        "\n",
        "# Discriminator: takes the frame and the next frame, and predicts whether the next frame is real or generated\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(128*128*2, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 1)\n",
        "\n",
        "    def forward(self, frame, next_frame):\n",
        "        # Flatten the frames\n",
        "        frame = frame.view(frame.size(0), -1)\n",
        "        next_frame = next_frame.view(next_frame.size(0), -1)\n",
        "\n",
        "        # Concatenate the frames\n",
        "        x = torch.cat([frame, next_frame], dim=1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# Step 3: Initializing the models, loss function, and optimizers\n",
        "\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for GANs\n",
        "# Example of using MSELoss instead of BCELoss\n",
        "# criterion = nn.MSELoss()\n",
        "optimizer_g = optim.Adam(generator.parameters(), lr=0.0001)\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0001)\n",
        "\n",
        "# Step 4: GAN training loop\n",
        "\n",
        "def train_gan(epochs=100):\n",
        "    for epoch in range(epochs):\n",
        "        for i, (first_frame, motion_vector, real_next_frame) in enumerate(data_loader):\n",
        "            # Train the discriminator\n",
        "            optimizer_d.zero_grad()\n",
        "\n",
        "            # Real frame pair (label=1)\n",
        "            real_label = torch.ones((first_frame.size(0), 1))\n",
        "            real_output = discriminator(first_frame, real_next_frame)\n",
        "            real_loss = criterion(real_output, real_label)\n",
        "\n",
        "            # Generated frame pair (label=0)\n",
        "            fake_next_frame = generator(first_frame, motion_vector)\n",
        "            fake_label = torch.zeros((first_frame.size(0), 1))\n",
        "            fake_output = discriminator(first_frame, fake_next_frame.detach())\n",
        "            fake_loss = criterion(fake_output, fake_label)\n",
        "\n",
        "            # Total discriminator loss\n",
        "            d_loss = real_loss + fake_loss\n",
        "            d_loss.backward()\n",
        "            optimizer_d.step()\n",
        "\n",
        "            # Train the generator\n",
        "            optimizer_g.zero_grad()\n",
        "            fake_output = discriminator(first_frame, fake_next_frame)\n",
        "            g_loss = criterion(fake_output, real_label)  # We want the generator to fool the discriminator\n",
        "            g_loss.backward()\n",
        "            optimizer_g.step()\n",
        "\n",
        "        # Logging the losses for both Generator and Discriminator\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] | D_loss: {d_loss.item()} | G_loss: {g_loss.item()}\")\n",
        "\n",
        "# Start training the GAN\n",
        "train_gan(epochs=100)  # Using a small number of epochs for demonstration purposes"
      ],
      "metadata": {
        "id": "JgxixuZPgPai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example: Generate images using the trained generator\n",
        "def generate_images(generator, first_frame, motion_vectors):\n",
        "    generated_sequence = []\n",
        "    current_frame = first_frame\n",
        "\n",
        "    for motion_vector in motion_vectors:\n",
        "        # Ensure motion_vector is correctly converted to tensor and has the correct shape\n",
        "        motion_vector = torch.tensor(motion_vector).unsqueeze(0).float()\n",
        "\n",
        "        # Optional: Print shapes to debug\n",
        "        print(f\"Current frame shape: {current_frame.shape}\")\n",
        "        print(f\"Motion vector shape: {motion_vector.shape}\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            next_frame = generator(current_frame, motion_vector)\n",
        "            generated_sequence.append(next_frame.squeeze().cpu().numpy() * 255)  # Store generated frames\n",
        "\n",
        "        current_frame = next_frame  # Update current frame for the next iteration\n",
        "\n",
        "    return generated_sequence\n",
        "\n",
        "# Test generation using first frame and motion vectors\n",
        "first_frame = torch.tensor(frames[0]).unsqueeze(0).unsqueeze(0).float() / 255.0\n",
        "generated_frames = generate_images(generator, first_frame, motion_vectors)\n"
      ],
      "metadata": {
        "id": "Zj8elk2dmmah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_generated_frames_horizontal(frames):\n",
        "    num_frames = len(frames)\n",
        "\n",
        "    # Create a horizontal figure with a subplot for each frame\n",
        "    fig, axes = plt.subplots(1, num_frames, figsize=(num_frames * 2, 4))  # Adjust figsize for wider output\n",
        "\n",
        "    for idx, frame in enumerate(frames):\n",
        "        axes[idx].imshow(frame, cmap='gray')\n",
        "        axes[idx].set_title(f\"Frame {idx + 1}\")\n",
        "        axes[idx].axis(\"off\")  # Hide axes\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to display frames horizontally\n",
        "display_generated_frames_horizontal(generated_frames)"
      ],
      "metadata": {
        "id": "9f1MbCFeluvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_frame = torch.tensor(frames[0]).unsqueeze(0).unsqueeze(0).float() / 255.0\n",
        "print(first_frame.shape)  # 입력된 첫 번째 프레임의 크기 확인\n"
      ],
      "metadata": {
        "id": "MnAM1jRSoz2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example: Visualize the generated frame vs real frame\n",
        "def visualize_frames(first_frame, real_next_frame, generated_frame):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # First frame\n",
        "    axes[0].imshow(first_frame.squeeze().cpu().numpy(), cmap='gray')\n",
        "    axes[0].set_title(\"First Frame\")\n",
        "\n",
        "    # Real next frame\n",
        "    axes[1].imshow(real_next_frame.squeeze().cpu().numpy(), cmap='gray')\n",
        "    axes[1].set_title(\"Real Next Frame\")\n",
        "\n",
        "    # Generated frame - detach before converting to numpy\n",
        "    axes[2].imshow(generated_frame.squeeze().detach().cpu().numpy(), cmap='gray')\n",
        "    axes[2].set_title(\"Generated Frame\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Example: Generate frames and visualize\n",
        "first_frame, motion_vector, real_next_frame = next(iter(data_loader))\n",
        "generated_frame = generator(first_frame, motion_vector)\n",
        "\n",
        "visualize_frames(first_frame, real_next_frame, generated_frame)\n"
      ],
      "metadata": {
        "id": "dwvQwD8Eo0Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.animation import FuncAnimation\n",
        "from IPython.display import HTML"
      ],
      "metadata": {
        "id": "OxP2azYFvgTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def animate_frames(predicted_frames):\n",
        "    \"\"\"\n",
        "    Create and display an animation from predicted frames in Jupyter Notebook.\n",
        "\n",
        "    Parameters:\n",
        "    predicted_frames (numpy array): Array of predicted frames, expected shape (num_frames, 128, 128, 3).\n",
        "    \"\"\"\n",
        "    num_frames = predicted_frames.shape[0]\n",
        "\n",
        "    # Create a figure\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Display the first frame initially\n",
        "    img = ax.imshow(predicted_frames[0], animated=True, cmap='gray')\n",
        "    ax.axis('off')  # Hide the axis for visual appeal\n",
        "\n",
        "    # Update function for the animation\n",
        "    def update(frame_num):\n",
        "        img.set_array(predicted_frames[frame_num])  # Update the image data with the new frame\n",
        "        return [img]\n",
        "\n",
        "    # Create the animation: FuncAnimation creates a new image every interval\n",
        "    ani = FuncAnimation(\n",
        "        fig, update, frames=num_frames, interval=200, blit=True  # interval sets the frame display time (in ms)\n",
        "    )\n",
        "\n",
        "    # Display the animation in Jupyter\n",
        "    plt.close(fig)  # Close the figure to prevent a static image from being displayed\n",
        "    return HTML(ani.to_jshtml())  # Display the animation in HTML format"
      ],
      "metadata": {
        "id": "BN_pfSAotD37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "animate_frames(np.array(generated_frames))"
      ],
      "metadata": {
        "id": "1EHA-4RavMGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CZ0MA5CUvSqh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}