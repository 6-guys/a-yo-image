{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNeyI1gl3So1f0S130SToLD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 데이터 불러오기"],"metadata":{"id":"ToynVwEENXuc"}},{"cell_type":"code","source":["from tensorflow.keras.datasets import mnist\n","(train_images, _), (_, _) = mnist.load_data()"],"metadata":{"id":"NNwd1KfPkkcQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_images = (train_images.astype('float32')-127.5) / 127.5 # -1~1 사이로 표준화\n","print(train_images.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GRYC_p36nIgM","executionInfo":{"status":"ok","timestamp":1718932652220,"user_tz":-540,"elapsed":51,"user":{"displayName":"허진경 (나자바바)","userId":"08806215878196109838"}},"outputId":"0c5cfca6-0b2b-43de-a32a-37821b90f7e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["float32\n"]}]},{"cell_type":"code","source":["import numpy as np\n","train_images = np.expand_dims(train_images, axis=-1)\n","print(train_images.shape) # channel last 이미지 데이터"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z9jo0yGwkkY9","executionInfo":{"status":"ok","timestamp":1718932652220,"user_tz":-540,"elapsed":33,"user":{"displayName":"허진경 (나자바바)","userId":"08806215878196109838"}},"outputId":"9eb8600d-0d18-46f6-c54b-eb0084bfb4d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(60000, 28, 28, 1)\n"]}]},{"cell_type":"code","source":["# 배치 데이터 만들기\n","import tensorflow as tf\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices(train_images).batch(256)\n","print(train_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lMy6dLWMQGut","executionInfo":{"status":"ok","timestamp":1718932652719,"user_tz":-540,"elapsed":529,"user":{"displayName":"허진경 (나자바바)","userId":"08806215878196109838"}},"outputId":"be1b2c7b-a30d-454e-cf7b-c671082b8ba2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<_BatchDataset element_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None)>\n"]}]},{"cell_type":"markdown","source":["# 생성자 모델"],"metadata":{"id":"Rhey6GdGNgPs"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","# 생성자\n","generator_model = Sequential([\n","    layers.Input(shape=(100,)), # 입력 노이즈의 shape(크기)\n","    layers.Dense(7*7*256, activation='elu'),\n","    layers.BatchNormalization(),\n","\n","    layers.Reshape((7,7,256)),\n","    layers.Conv2DTranspose(128, 5, padding='same', activation='elu'), # 7x7x128\n","    layers.BatchNormalization(),\n","\n","    layers.Conv2DTranspose(64, 5, strides=(2,2), padding='same', activation='elu'), # 14x14x64\n","    layers.BatchNormalization(),\n","\n","    layers.Conv2DTranspose(1, 5, strides=(2,2), padding='same', activation='tanh') # 28x28x1 데이터\n","])\n","generator_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tTnWuv2XkkWg","executionInfo":{"status":"ok","timestamp":1718932653254,"user_tz":-540,"elapsed":539,"user":{"displayName":"허진경 (나자바바)","userId":"08806215878196109838"}},"outputId":"39a10c12-c607-4593-ae83-ee2802b361b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 12544)             1266944   \n","                                                                 \n"," batch_normalization (Batch  (None, 12544)             50176     \n"," Normalization)                                                  \n","                                                                 \n"," reshape (Reshape)           (None, 7, 7, 256)         0         \n","                                                                 \n"," conv2d_transpose (Conv2DTr  (None, 7, 7, 128)         819328    \n"," anspose)                                                        \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 7, 7, 128)         512       \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_transpose_1 (Conv2D  (None, 14, 14, 64)        204864    \n"," Transpose)                                                      \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 14, 14, 64)        256       \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_transpose_2 (Conv2D  (None, 28, 28, 1)         1601      \n"," Transpose)                                                      \n","                                                                 \n","=================================================================\n","Total params: 2343681 (8.94 MB)\n","Trainable params: 2318209 (8.84 MB)\n","Non-trainable params: 25472 (99.50 KB)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# 판별자\n","discriminator_model = Sequential([\n","    layers.Input(shape=(28,28,1)),\n","    layers.Conv2D(64, (5,5), strides=(2,2), padding='same', activation='elu'),\n","    layers.Dropout(0.3),\n","\n","    layers.Conv2D(128, (5,5), strides=(2,2), padding='same', activation='elu'),\n","    layers.Dropout(0.3),\n","\n","    layers.Flatten(),\n","    layers.Dense(1)\n","])\n","discriminator_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IFyUnYvRkkTK","executionInfo":{"status":"ok","timestamp":1718932653254,"user_tz":-540,"elapsed":42,"user":{"displayName":"허진경 (나자바바)","userId":"08806215878196109838"}},"outputId":"4050e1ed-2bb2-4a7a-ef43-44d0dbb578b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 14, 14, 64)        1664      \n","                                                                 \n"," dropout (Dropout)           (None, 14, 14, 64)        0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 7, 7, 128)         204928    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 6272)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 6273      \n","                                                                 \n","=================================================================\n","Total params: 212865 (831.50 KB)\n","Trainable params: 212865 (831.50 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","\n","def generator_loss(fake_output):\n","    return cross_entropy(tf.ones_like(fake_output), fake_output) # 1\n","\n","def discriminator_loss(real_output, fake_output):\n","    real_loss = cross_entropy(tf.ones_like(real_output), real_output) # 1\n","    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output) # 0\n","    total_loss = real_loss + fake_loss\n","    return total_loss\n","\n","generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n","discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"],"metadata":{"id":"ci1dsI2MkkP-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@tf.function\n","def train_step(images):\n","    noise = tf.random.normal([256, 100]) # 이미지 생성을 위한 노이즈 입력\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape: # 미분을 위한 도구, loss를 계산\n","        # loss를 계산하려면 모델, 손실함수, 입력값 X와 y, 파라미터가 있어야 합니다.\n","        generated_image = generator_model(noise, training=True)\n","        fake_output = discriminator_model(generated_image, training=True)\n","        real_output = discriminator_model(images, training=True)\n","\n","        gen_loss = generator_loss(fake_output)\n","        dis_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(gen_loss, generator_model.trainable_variables)\n","    gradients_of_discriminator = dis_tape.gradient(dis_loss, discriminator_model.trainable_variables)\n","\n","    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator_model.trainable_variables))\n","    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator_model.trainable_variables))\n"],"metadata":{"id":"EBwSZlSBkkMn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from tqdm import tqdm # 반복문 실행상태 표시기\n","sample_noise = tf.random.normal([9, 100]) # 9개 샘플 이미지를 만들기 위한 노이즈\n","epochs = 200\n","for epoch in range(epochs):\n","    for image_batch in tqdm(train_dataset):\n","        train_step(image_batch)\n","        # print('.', end='')\n","    # print(f'{epoch+1}')\n","\n","    # 훈련과정을 보여주기 위한 코드입니다.\n","    sample_images = generator_model(sample_noise, training=False) # 매 학습 후 이미지를 생성합니다.\n","\n","    plt.figure(figsize=(3,3)) # 도화지 크기를 가로세로 5인치 크기로 설정.\n","    for i in range(sample_images.shape[0]): # 9개 이미지\n","        plt.subplot(3,3, i+1) # 3행 3열로 나눈 도화지 영역의 i+1 번째에 그림을 그리겠습니다.\n","        plt.imshow(sample_images[i,...], cmap='gray') # sample_image[i,:,:,0]\n","        plt.axis('off')\n","    # plt에 그려진 이미지를 파일에 저장\n","    plt.savefig(f'epoch-{epoch:04d}.png')\n","    plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1KDwJKuRi8-mBFxawRrJvaBlwqg-0AY7H"},"id":"Ie9z_Jwikj_j","executionInfo":{"status":"ok","timestamp":1718935026882,"user_tz":-540,"elapsed":2373650,"user":{"displayName":"허진경 (나자바바)","userId":"08806215878196109838"}},"outputId":"e6766824-390b-496e-d20f-a57884e8f21c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"3SulVmPBk8hu"},"execution_count":null,"outputs":[]}]}